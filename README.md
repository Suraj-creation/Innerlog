<p align="center">
  <h1 align="center">ğŸ§  InnerLog â€” EdgeMemory</h1>
  <p align="center">
    <strong>A laptop-buildable, fully open-source personal causal intelligence system</strong>
  </p>
  <p align="center">
    <em>Your entire life stream â†’ structured, time-aware, causal knowledge graph â€” all running 100% locally on your device.</em>
  </p>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#api-reference">API</a> â€¢
  <a href="#web-ui">Web UI</a> â€¢
  <a href="#configuration">Configuration</a> â€¢
  <a href="#project-structure">Structure</a> â€¢
  <a href="#roadmap">Roadmap</a>
</p>

---

## The Problem

Current AI assistants suffer from critical limitations:

| Limitation | Impact | InnerLog Solution |
|---|---|---|
| **No deep personal grounding** | LLMs know fragments from short chats; beliefs and goals never become stable memory | Continuous structured, persistent memory |
| **Context-window forgetting** | Past reasoning is lost when pushed out of context | Infinite temporal memory with compression |
| **Weak non-temporal memory** | No understanding of *when* or *how* thinking evolved | Time-aware causal memory graph |
| **Cloud-first, privacy-weak** | Server-side logs expose personal data | **100% on-device** â€” zero cloud dependency |

## The Core Insight

> **Memory â‰  Logging. Memory = Intentional Brain Duplication.**

The LLM is **not** the brain. The LLM is a **reasoning lens** over structured, evolving memory. Memory must be explicit, inspectable, and causal. Retrieval must be agentic and multi-step, not top-K similarity.

---

## Features

### ğŸ™ï¸ Multi-Modal Ingestion
- **Text input** â€” Type thoughts, reflections, decisions directly
- **Voice input** â€” Local Whisper-based speech-to-text (no cloud ASR)
- **Automatic classification** â€” Lightweight classifiers (~50ms) categorize memory type, emotion, and importance
- **Entity extraction** â€” Identifies people, projects, places, and concepts with fuzzy resolution

### ğŸ—„ï¸ Multi-Layer Storage
- **Vector Store** (FAISS) â€” Semantic similarity search over memory embeddings
- **Relational DB** (DuckDB) â€” Structured metadata with temporal indexing
- **Knowledge Graph** (NetworkX) â€” Entity relationships as triples with traversal
- **Causal Links** â€” Explicit cause-effect chains between memories

### ğŸ” Hybrid Multi-Channel Retrieval
- **Dense retrieval** â€” Embedding-based semantic search
- **Sparse retrieval** â€” BM25 keyword matching
- **Graph traversal** â€” Follow entity and causal relationships
- **SQL filtering** â€” Exact temporal/type/topic filters
- **Reciprocal Rank Fusion** â€” Merges all channels into one ranked result

### ğŸ¤– Agent-Based Reasoning
- **Timeline Agent** â€” Reconstruct chronological sequences ("What happened last month?")
- **Causal Agent** â€” Trace cause-effect chains ("Why did I make that decision?")
- **Arbitration Agent** â€” Resolve conflicting memories and belief changes
- **Orchestrator** â€” Intelligent routing with multi-step query decomposition

### ğŸ§ª Local LLM Integration
- **Ollama** â€” Primary provider (Phi-3, Mistral 7B, Qwen2.5)
- **LM Studio** â€” Secondary provider with automatic failover
- **Dual-provider failover** â€” If one backend is down, the other takes over seamlessly

### ğŸŒ Full Web Command Center
- Dashboard with system health monitoring
- Memory ingestion (text & voice)
- Memory browser with timeline view
- Chat-like query interface with reasoning traces
- Knowledge graph visualization
- Real-time WebSocket updates

### ğŸ”’ Privacy First
- **100% offline** â€” No network calls, no telemetry
- **All processing local** â€” LLM, embeddings, ASR, everything on-device
- **Your data stays yours** â€” DuckDB + FAISS files on your disk

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGEMEMORY SYSTEM                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   INPUT      â”‚     â”‚              INGESTION PIPELINE                â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  Voice       â”‚â”€â”€â”€â”€â–¶â”‚  â”‚ Whisper â”‚â”€â–¶â”‚ Memory   â”‚â”€â–¶â”‚ Embedding +  â”‚  â”‚   â”‚
â”‚  â”‚  Text        â”‚     â”‚  â”‚  (ASR)  â”‚  â”‚ Builder  â”‚  â”‚ Classify     â”‚  â”‚   â”‚
â”‚  â”‚  Reflection  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        STORAGE LAYER                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ Vector DB  â”‚  â”‚ Relational â”‚  â”‚  Causal    â”‚  â”‚  Knowledge   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  (FAISS)   â”‚  â”‚    DB      â”‚  â”‚   Graph    â”‚  â”‚    Graph     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚            â”‚  â”‚ (DuckDB)   â”‚  â”‚   Links    â”‚  â”‚  (Triples)   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    MULTI-CHANNEL RETRIEVAL                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Dense   â”‚  â”‚ Sparse  â”‚  â”‚  Graph  â”‚  â”‚  SQL    â”‚  â”‚Re-rankerâ”‚  â”‚   â”‚
â”‚  â”‚  â”‚(Embed)  â”‚  â”‚ (BM25)  â”‚  â”‚Traverse â”‚  â”‚ Filter  â”‚  â”‚(Fusion) â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         AGENT LAYER                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ Timeline â”‚  â”‚ Causal   â”‚  â”‚Arbitrate â”‚  â”‚   Orchestrator     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Agent   â”‚  â”‚  Agent   â”‚  â”‚  Agent   â”‚  â”‚  (Router/Planner)  â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    LOCAL LLM (Reasoning Only)                        â”‚   â”‚
â”‚  â”‚               Phi-3 / Mistral 7B via Ollama + LM Studio              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

**Ingestion (Memory Creation):**
```
Input (voice/text) â†’ Whisper ASR â†’ Memory Builder â†’ Classification + Embedding
                                                          â†“
                    Entity Resolution â† Storage (Vector + SQL + Graph)
                                                          â†“
                                           Store + Link + Update
```

**Query (Reasoning):**
```
Query â†’ Intent Detection â†’ Multi-Channel Retrieval â†’ Fusion + Re-ranking
                                                          â†“
             Answer + Evidence â† LLM Reasoning â† Agent Orchestration
```

---

## Quick Start

### Prerequisites

- **Python 3.10+**
- **Ollama** installed and running ([ollama.com](https://ollama.com))
- **8GB+ RAM** (no GPU required)

### 1. Clone & Setup

```bash
git clone https://github.com/Suraj-creation/Innerlog.git
cd Innerlog

# Create virtual environment
python -m venv venv

# Activate (Windows)
.\venv\Scripts\Activate

# Activate (macOS/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Pull Required Models

```bash
# LLM for reasoning
ollama pull phi3

# Embedding model
ollama pull nomic-embed-text
```

### 3. Run

```bash
python run.py
```

The server starts at **http://localhost:8000**. Open it in your browser to access the Web Command Center.

---

## Web UI

The Web Command Center is a single-page application served directly by the FastAPI backend â€” no npm or build steps required.

### Dashboard
System health overview showing status of all components (Ollama, FAISS, DuckDB, embeddings), memory count, and storage statistics.

### Memory Ingestion
- **Text input** â€” Type memories, reflections, decisions
- **Voice recording** â€” Record via browser microphone, transcribed locally by Whisper
- Real-time classification preview (type, emotion, importance)

### Memory Browser
- Chronological timeline of all memories
- Filter by type (episodic/semantic/procedural/reflective), topic, emotion
- Full-text search across all memories
- Memory detail view with causal links and entity connections

### Query Interface
- Chat-like interface for asking questions about your memories
- Shows reasoning trace, evidence cards, and confidence scores
- Agent routing information visible for transparency

### Knowledge Graph
- Interactive visualization of entity relationships
- Explore connections between people, projects, topics, and events

---

## API Reference

### Health & System

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | System health check |
| `GET` | `/api/system/stats` | Memory count, storage stats |

### Memory Ingestion

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/memories/ingest/text` | Ingest text memory |
| `POST` | `/api/memories/ingest/audio` | Ingest audio file (Whisper transcription) |

### Memory Browser

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/memories` | List memories (paginated) |
| `GET` | `/api/memories/search?q=...` | Search memories |
| `GET` | `/api/memories/{id}` | Get memory detail |
| `DELETE` | `/api/memories/{id}` | Delete memory |

### Query

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/query` | Query the memory system with natural language |

### Knowledge Graph

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/graph/entities` | Get all entities and relations |
| `GET` | `/api/graph/neighbors/{entity}` | Get entity neighbors |

### WebSocket

| Endpoint | Description |
|----------|-------------|
| `WS /ws` | Real-time updates (memory ingested, status changes) |

Full interactive API documentation available at **http://localhost:8000/docs** (Swagger UI).

---

## Configuration

All settings are in [`configs/config.yaml`](configs/config.yaml):

```yaml
# LLM Settings
llm:
  provider: "ollama"              # "ollama" or "lmstudio"
  model: "phi3"                   # Model name
  temperature: 0.7
  max_tokens: 1024
  lmstudio:
    model: "mistral-7b-instruct-v0.1"
    base_url: "http://localhost:1234"

# Embedding Settings
embeddings:
  provider: "ollama"
  model: "nomic-embed-text"
  dimension: 768

# Retrieval Fusion Weights
retrieval:
  fusion_weights:
    dense: 0.4                    # Semantic similarity
    sparse: 0.2                   # Keyword matching
    graph: 0.2                    # Entity/causal traversal
    sql: 0.2                      # Exact filters

# Agent Settings
agents:
  enabled: [timeline, causal, arbitration]
  fallback_agent: "timeline"
```

---

## Project Structure

```
Innerlog/
â”œâ”€â”€ run.py                    # Entry point â€” starts the server
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml           # System configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py           # Central orchestrator
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ server.py         # FastAPI endpoints + WebSocket
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ asr.py            # Whisper speech-to-text
â”‚   â”‚   â”œâ”€â”€ memory_builder.py # Memory event construction
â”‚   â”‚   â”œâ”€â”€ classifier.py     # Lightweight classifiers
â”‚   â”‚   â”œâ”€â”€ entity_extractor.py  # Entity extraction (LLM + regex)
â”‚   â”‚   â””â”€â”€ entity_resolver.py   # Fuzzy entity resolution
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ vector_store.py   # FAISS vector storage
â”‚   â”‚   â”œâ”€â”€ relational_db.py  # DuckDB relational storage
â”‚   â”‚   â””â”€â”€ knowledge_graph.py # NetworkX knowledge graph
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ dense_retriever.py   # Embedding-based retrieval
â”‚   â”‚   â”œâ”€â”€ sparse_retriever.py  # BM25 retrieval
â”‚   â”‚   â”œâ”€â”€ graph_retriever.py   # Graph traversal retrieval
â”‚   â”‚   â”œâ”€â”€ sql_retriever.py     # SQL filter retrieval
â”‚   â”‚   â””â”€â”€ fusion.py           # Reciprocal Rank Fusion
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base_agent.py     # Agent interface
â”‚   â”‚   â”œâ”€â”€ orchestrator.py   # Multi-agent routing & chaining
â”‚   â”‚   â”œâ”€â”€ timeline_agent.py # Chronological queries
â”‚   â”‚   â”œâ”€â”€ causal_agent.py   # Cause-effect reasoning
â”‚   â”‚   â””â”€â”€ arbitration_agent.py # Conflict resolution
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ local_llm.py      # Ollama + LM Studio dual-provider
â”‚   â”‚   â””â”€â”€ prompts.py        # Prompt templates
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ memory_types.py   # Pydantic data models
â”‚   â”‚   â””â”€â”€ embeddings.py     # Embedding model wrapper
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ config.py         # YAML config loader
â”‚   â””â”€â”€ web/
â”‚       â””â”€â”€ index.html        # Web Command Center (SPA)
â”œâ”€â”€ data/                     # Runtime data (gitignored)
â”‚   â”œâ”€â”€ memories.duckdb       # Relational database
â”‚   â”œâ”€â”€ faiss_index.index     # Vector embeddings
â”‚   â””â”€â”€ knowledge_graph.json  # Entity graph
â”œâ”€â”€ plan.md                   # Full implementation plan
â”œâ”€â”€ model_strategy.md         # Model selection strategy
â””â”€â”€ DL-project.md             # Project overview
```

---

## Memory Types

InnerLog classifies every memory into one of four types:

| Type | Description | Example | Decay Rate |
|------|-------------|---------|------------|
| **Episodic** | What happened (events, conversations) | "Had a meeting with John about Project X" | Medium |
| **Semantic** | What you learned (facts, insights) | "Transformers use self-attention" | Low |
| **Procedural** | How you do things (habits, methods) | "I always review code before committing" | Very Low |
| **Reflective** | Why you changed (meta-cognition) | "I realized I was avoiding hard problems" | Low |

---

## Performance Targets

| Metric | Target |
|--------|--------|
| Ingestion Latency | < 500ms per text memory |
| Query Latency (avg) | < 2000ms |
| Query Latency (P95) | < 3500ms |
| Memory Footprint | < 4GB RAM with 10,000 memories |
| Storage | < 1GB per year of daily journaling |
| LLM Fallback Rate | < 15% (most classification by lightweight models) |
| Precision@5 | > 65% |
| Recall@10 | > 70% |

---

## Tech Stack

| Component | Technology |
|-----------|------------|
| **LLM** | Ollama (Phi-3, Mistral 7B) + LM Studio |
| **Embeddings** | nomic-embed-text via Ollama |
| **ASR** | OpenAI Whisper (local) |
| **Vector Store** | FAISS |
| **Relational DB** | DuckDB |
| **Knowledge Graph** | NetworkX |
| **Sparse Retrieval** | BM25 (rank-bm25) |
| **Entity Resolution** | RapidFuzz |
| **Web Framework** | FastAPI + Uvicorn |
| **Frontend** | Vanilla HTML/CSS/JS (no build step) |
| **Data Models** | Pydantic v2 |

---

## Roadmap

- [x] Core pipeline (ingestion â†’ storage â†’ retrieval â†’ agents â†’ LLM)
- [x] Multi-layer storage (FAISS + DuckDB + Knowledge Graph)
- [x] Hybrid retrieval with Reciprocal Rank Fusion
- [x] Agent-based reasoning (Timeline, Causal, Arbitration)
- [x] Dual LLM provider (Ollama + LM Studio failover)
- [x] Web Command Center with real-time updates
- [x] Voice ingestion via Whisper
- [ ] Memory consolidation (hierarchical summarization)
- [ ] Belief evolution tracker
- [ ] Causal link detection (explicit + inferred)
- [ ] Evaluation framework with synthetic datasets
- [ ] Fine-tuned lightweight classifiers (SetFit)
- [ ] Mobile deployment (ONNX export)
- [ ] Multi-modal memories (images, documents)

---

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is open-source and available under the [MIT License](LICENSE).

---

<p align="center">
  <strong>Built with the philosophy: Memory â‰  Logging. Memory = Intentional Brain Duplication.</strong>
</p>
